{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d151dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9996c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946a3423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------Get Text Data------------------------------\n",
    "with open('../Data/shakespeare.txt','r',encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7706b175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02260b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bud buriest thy content,\\n  And tender churl mak'st waste in niggarding:\\n    Pity the world, or else this glutton be,\\n    To eat the world's due, by the grave and thee.\\n\\n\\n                     2\\n  When forty winters shall besiege thy brow,\\n  And dig deep trenches in thy beauty's field,\\n  Thy youth's proud livery so gazed on now,\\n  Will be a tattered weed of small worth held:  \\n  Then being asked, where all thy beauty lies,\\n  Where all the treasure of thy lusty days;\\n  To say within thine own deep su\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000] #1st 1k char --raw str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba4decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bud buriest thy content,\n",
      "  And tender churl mak'st waste in niggarding:\n",
      "    Pity the world, or else this glutton be,\n",
      "    To eat the world's due, by the grave and thee.\n",
      "\n",
      "\n",
      "                     2\n",
      "  When forty winters shall besiege thy brow,\n",
      "  And dig deep trenches in thy beauty's field,\n",
      "  Thy youth's proud livery so gazed on now,\n",
      "  Will be a tattered weed of small worth held:  \n",
      "  Then being asked, where all thy beauty lies,\n",
      "  Where all the treasure of thy lusty days;\n",
      "  To say within thine own deep su\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "145155f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f453fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------Encode Entire Text-----------------------\n",
    "#Figure out all unique characters in the text\n",
    "all_characters = set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167df4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '>',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '|',\n",
       " '}'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b51a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_characters) #total 84 unique char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91c0fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder will take a char & returns its encoded number\n",
    "#Decoder would do the opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86e1f397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'I')\n",
      "(1, 'o')\n",
      "(2, '.')\n",
      "(3, ';')\n",
      "(4, 'T')\n",
      "(5, 'f')\n",
      "(6, 'O')\n",
      "(7, '?')\n",
      "(8, '5')\n",
      "(9, 'K')\n",
      "(10, 'p')\n",
      "(11, 'k')\n",
      "(12, 'R')\n",
      "(13, 'Q')\n",
      "(14, '[')\n",
      "(15, 't')\n",
      "(16, 'J')\n",
      "(17, '_')\n",
      "(18, 'M')\n",
      "(19, 'a')\n",
      "(20, '1')\n",
      "(21, 'C')\n",
      "(22, 'h')\n",
      "(23, '|')\n",
      "(24, 'g')\n",
      "(25, '0')\n",
      "(26, 'i')\n",
      "(27, 'S')\n",
      "(28, 'F')\n",
      "(29, '\\n')\n",
      "(30, 'z')\n",
      "(31, '<')\n",
      "(32, '3')\n",
      "(33, 'Z')\n",
      "(34, 'H')\n",
      "(35, 'u')\n",
      "(36, '!')\n",
      "(37, 'A')\n",
      "(38, 'q')\n",
      "(39, 'E')\n",
      "(40, '8')\n",
      "(41, '6')\n",
      "(42, ':')\n",
      "(43, '(')\n",
      "(44, 'G')\n",
      "(45, ']')\n",
      "(46, \"'\")\n",
      "(47, '-')\n",
      "(48, 'Y')\n",
      "(49, 'w')\n",
      "(50, 'c')\n",
      "(51, 'j')\n",
      "(52, 'v')\n",
      "(53, '>')\n",
      "(54, 'r')\n",
      "(55, 'd')\n",
      "(56, 'x')\n",
      "(57, 'B')\n",
      "(58, '7')\n",
      "(59, 's')\n",
      "(60, 'b')\n",
      "(61, ',')\n",
      "(62, 'N')\n",
      "(63, '9')\n",
      "(64, ' ')\n",
      "(65, '2')\n",
      "(66, 'm')\n",
      "(67, 'y')\n",
      "(68, 'X')\n",
      "(69, 'n')\n",
      "(70, 'l')\n",
      "(71, '4')\n",
      "(72, 'V')\n",
      "(73, '}')\n",
      "(74, 'e')\n",
      "(75, ')')\n",
      "(76, 'L')\n",
      "(77, 'U')\n",
      "(78, 'P')\n",
      "(79, 'D')\n",
      "(80, '\"')\n",
      "(81, '&')\n",
      "(82, '`')\n",
      "(83, 'W')\n"
     ]
    }
   ],
   "source": [
    "#enumerate(all_characters) would assign number to unique char\n",
    "for pair in enumerate(all_characters):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d40eec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num --> Letter\n",
    "decoder = dict(enumerate(all_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef6179b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'I',\n",
       " 1: 'o',\n",
       " 2: '.',\n",
       " 3: ';',\n",
       " 4: 'T',\n",
       " 5: 'f',\n",
       " 6: 'O',\n",
       " 7: '?',\n",
       " 8: '5',\n",
       " 9: 'K',\n",
       " 10: 'p',\n",
       " 11: 'k',\n",
       " 12: 'R',\n",
       " 13: 'Q',\n",
       " 14: '[',\n",
       " 15: 't',\n",
       " 16: 'J',\n",
       " 17: '_',\n",
       " 18: 'M',\n",
       " 19: 'a',\n",
       " 20: '1',\n",
       " 21: 'C',\n",
       " 22: 'h',\n",
       " 23: '|',\n",
       " 24: 'g',\n",
       " 25: '0',\n",
       " 26: 'i',\n",
       " 27: 'S',\n",
       " 28: 'F',\n",
       " 29: '\\n',\n",
       " 30: 'z',\n",
       " 31: '<',\n",
       " 32: '3',\n",
       " 33: 'Z',\n",
       " 34: 'H',\n",
       " 35: 'u',\n",
       " 36: '!',\n",
       " 37: 'A',\n",
       " 38: 'q',\n",
       " 39: 'E',\n",
       " 40: '8',\n",
       " 41: '6',\n",
       " 42: ':',\n",
       " 43: '(',\n",
       " 44: 'G',\n",
       " 45: ']',\n",
       " 46: \"'\",\n",
       " 47: '-',\n",
       " 48: 'Y',\n",
       " 49: 'w',\n",
       " 50: 'c',\n",
       " 51: 'j',\n",
       " 52: 'v',\n",
       " 53: '>',\n",
       " 54: 'r',\n",
       " 55: 'd',\n",
       " 56: 'x',\n",
       " 57: 'B',\n",
       " 58: '7',\n",
       " 59: 's',\n",
       " 60: 'b',\n",
       " 61: ',',\n",
       " 62: 'N',\n",
       " 63: '9',\n",
       " 64: ' ',\n",
       " 65: '2',\n",
       " 66: 'm',\n",
       " 67: 'y',\n",
       " 68: 'X',\n",
       " 69: 'n',\n",
       " 70: 'l',\n",
       " 71: '4',\n",
       " 72: 'V',\n",
       " 73: '}',\n",
       " 74: 'e',\n",
       " 75: ')',\n",
       " 76: 'L',\n",
       " 77: 'U',\n",
       " 78: 'P',\n",
       " 79: 'D',\n",
       " 80: '\"',\n",
       " 81: '&',\n",
       " 82: '`',\n",
       " 83: 'W'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7efea85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letter --> num\n",
    "encoder = {char: ind for ind,char in decoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3536b86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 0,\n",
       " 'o': 1,\n",
       " '.': 2,\n",
       " ';': 3,\n",
       " 'T': 4,\n",
       " 'f': 5,\n",
       " 'O': 6,\n",
       " '?': 7,\n",
       " '5': 8,\n",
       " 'K': 9,\n",
       " 'p': 10,\n",
       " 'k': 11,\n",
       " 'R': 12,\n",
       " 'Q': 13,\n",
       " '[': 14,\n",
       " 't': 15,\n",
       " 'J': 16,\n",
       " '_': 17,\n",
       " 'M': 18,\n",
       " 'a': 19,\n",
       " '1': 20,\n",
       " 'C': 21,\n",
       " 'h': 22,\n",
       " '|': 23,\n",
       " 'g': 24,\n",
       " '0': 25,\n",
       " 'i': 26,\n",
       " 'S': 27,\n",
       " 'F': 28,\n",
       " '\\n': 29,\n",
       " 'z': 30,\n",
       " '<': 31,\n",
       " '3': 32,\n",
       " 'Z': 33,\n",
       " 'H': 34,\n",
       " 'u': 35,\n",
       " '!': 36,\n",
       " 'A': 37,\n",
       " 'q': 38,\n",
       " 'E': 39,\n",
       " '8': 40,\n",
       " '6': 41,\n",
       " ':': 42,\n",
       " '(': 43,\n",
       " 'G': 44,\n",
       " ']': 45,\n",
       " \"'\": 46,\n",
       " '-': 47,\n",
       " 'Y': 48,\n",
       " 'w': 49,\n",
       " 'c': 50,\n",
       " 'j': 51,\n",
       " 'v': 52,\n",
       " '>': 53,\n",
       " 'r': 54,\n",
       " 'd': 55,\n",
       " 'x': 56,\n",
       " 'B': 57,\n",
       " '7': 58,\n",
       " 's': 59,\n",
       " 'b': 60,\n",
       " ',': 61,\n",
       " 'N': 62,\n",
       " '9': 63,\n",
       " ' ': 64,\n",
       " '2': 65,\n",
       " 'm': 66,\n",
       " 'y': 67,\n",
       " 'X': 68,\n",
       " 'n': 69,\n",
       " 'l': 70,\n",
       " '4': 71,\n",
       " 'V': 72,\n",
       " '}': 73,\n",
       " 'e': 74,\n",
       " ')': 75,\n",
       " 'L': 76,\n",
       " 'U': 77,\n",
       " 'P': 78,\n",
       " 'D': 79,\n",
       " '\"': 80,\n",
       " '&': 81,\n",
       " '`': 82,\n",
       " 'W': 83}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00dedc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure encoder & decoder match -->represent the same char with num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d03ac2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all txt & encode it so it has numerical info aspect to it\n",
    "encoded_text = np.array([encoder[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "803a3dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
       "       64, 64, 64, 64, 64, 20, 29, 64, 64, 28, 54,  1, 66, 64,  5, 19, 26,\n",
       "       54, 74, 59, 15, 64, 50, 54, 74, 19, 15, 35, 54, 74, 59, 64, 49, 74,\n",
       "       64, 55, 74, 59, 26, 54, 74, 64, 26, 69, 50, 54, 74, 19, 59, 74, 61,\n",
       "       29, 64, 64,  4, 22, 19, 15, 64, 15, 22, 74, 54, 74, 60, 67, 64, 60,\n",
       "       74, 19, 35, 15, 67, 46, 59, 64, 54,  1, 59, 74, 64, 66, 26, 24, 22,\n",
       "       15, 64, 69, 74, 52, 74, 54, 64, 55, 26, 74, 61, 29, 64, 64, 57, 35,\n",
       "       15, 64, 19, 59, 64, 15, 22, 74, 64, 54, 26, 10, 74, 54, 64, 59, 22,\n",
       "        1, 35, 70, 55, 64, 60, 67, 64, 15, 26, 66, 74, 64, 55, 74, 50, 74,\n",
       "       19, 59, 74, 61, 29, 64, 64, 34, 26, 59, 64, 15, 74, 69, 55, 74, 54,\n",
       "       64, 22, 74, 26, 54, 64, 66, 26, 24, 22, 15, 64, 60, 74, 19, 54, 64,\n",
       "       22, 26, 59, 64, 66, 74, 66,  1, 54, 67, 42, 29, 64, 64, 57, 35, 15,\n",
       "       64, 15, 22,  1, 35, 64, 50,  1, 69, 15, 54, 19, 50, 15, 74, 55, 64,\n",
       "       15,  1, 64, 15, 22, 26, 69, 74, 64,  1, 49, 69, 64, 60, 54, 26, 24,\n",
       "       22, 15, 64, 74, 67, 74, 59, 61, 29, 64, 64, 28, 74, 74, 55, 46, 59,\n",
       "       15, 64, 15, 22, 67, 64, 70, 26, 24, 22, 15, 46, 59, 64,  5, 70, 19,\n",
       "       66, 74, 64, 49, 26, 15, 22, 64, 59, 74, 70,  5, 47, 59, 35, 60, 59,\n",
       "       15, 19, 69, 15, 26, 19, 70, 64,  5, 35, 74, 70, 61, 29, 64, 64, 18,\n",
       "       19, 11, 26, 69, 24, 64, 19, 64,  5, 19, 66, 26, 69, 74, 64, 49, 22,\n",
       "       74, 54, 74, 64, 19, 60, 35, 69, 55, 19, 69, 50, 74, 64, 70, 26, 74,\n",
       "       59, 61, 29, 64, 64,  4, 22, 67, 64, 59, 74, 70,  5, 64, 15, 22, 67,\n",
       "       64,  5,  1, 74, 61, 64, 15,  1, 64, 15, 22, 67, 64, 59, 49, 74, 74,\n",
       "       15, 64, 59, 74, 70,  5, 64, 15,  1,  1, 64, 50, 54, 35, 74, 70, 42,\n",
       "       29, 64, 64,  4, 22,  1, 35, 64, 15, 22, 19, 15, 64, 19, 54, 15, 64,\n",
       "       69,  1, 49, 64, 15, 22, 74, 64, 49,  1, 54, 70, 55, 46, 59, 64,  5,\n",
       "       54, 74, 59, 22, 64,  1, 54, 69, 19, 66, 74, 69, 15, 61, 29, 64, 64,\n",
       "       37, 69, 55, 64,  1, 69, 70, 67, 64, 22, 74, 54, 19, 70, 55, 64, 15,\n",
       "        1, 64, 15, 22, 74, 64, 24, 19, 35, 55, 67, 64, 59, 10, 54, 26, 69,\n",
       "       24, 61, 29, 64, 64, 83, 26, 15, 22, 26, 69, 64, 15, 22, 26, 69, 74,\n",
       "       64,  1, 49, 69, 64, 60, 35])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0e7b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------One Hot Encoding-------------------------------\n",
    "#we need to one-hot encode our data inorder for it to work with the network structure. \n",
    "def one_hot_encoder(encoded_text, num_uni_chars):\n",
    "    #encode_text --> batch of encoded text\n",
    "    #num_uni_chars --> len(set(text))\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    encoded_text : batch of encoded text\n",
    "    \n",
    "    num_uni_chars = number of unique characters (len(set(text)))\n",
    "    '''\n",
    "    \n",
    "    # METHOD FROM:\n",
    "    # https://stackoverflow.com/questions/29831489/convert-encoded_textay-of-indices-to-1-hot-encoded-numpy-encoded_textay\n",
    "      \n",
    "    # Create a placeholder for zeros.\n",
    "    one_hot = np.zeros((encoded_text.size, num_uni_chars))\n",
    "    \n",
    "    # Convert data type for later use with pytorch (errors if we dont!)\n",
    "    one_hot = one_hot.astype(np.float32)\n",
    "\n",
    "    # Using fancy indexing fill in the 1s at the correct index locations\n",
    "    one_hot[np.arange(one_hot.shape[0]), encoded_text.flatten()] = 1.0\n",
    "    \n",
    "\n",
    "    # Reshape it so it matches the batch sahe\n",
    "    one_hot = one_hot.reshape((*encoded_text.shape, num_uni_chars))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a47774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02ae69f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "012afeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder(arr,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374109e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d80d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51498742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------Creating Training Batches----------------------\n",
    "#create a function that will generate batches of characters along with the next character in the sequence as a label\n",
    "example_text = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6fd3041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8234917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we wanted 5 batches\n",
    "example_text.reshape((5,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40e5366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(encoded_text, samp_per_batch=10, seq_len=50):\n",
    "    \n",
    "    '''\n",
    "    Generate (using yield) batches for training.\n",
    "    \n",
    "    X: Encoded Text of length seq_len\n",
    "    Y: Encoded Text shifted by one\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    X:\n",
    "    \n",
    "    [[1 2 3]]\n",
    "    \n",
    "    Y:\n",
    "    \n",
    "    [[ 2 3 4]]\n",
    "    \n",
    "    encoded_text : Complete Encoded Text to make batches from\n",
    "    batch_size : Number of samples per batch\n",
    "    seq_len : Length of character sequence\n",
    "       \n",
    "    '''\n",
    "    \n",
    "    # Total number of characters per batch\n",
    "    # Example: If samp_per_batch is 2 and seq_len is 50, then 100\n",
    "    # characters come out per batch.\n",
    "    char_per_batch = samp_per_batch * seq_len\n",
    "    \n",
    "    \n",
    "    # Number of batches available to make\n",
    "    # Use int() to roun to nearest integer\n",
    "    num_batches_avail = int(len(encoded_text)/char_per_batch)\n",
    "    \n",
    "    # Cut off end of encoded_text that\n",
    "    # won't fit evenly into a batch\n",
    "    encoded_text = encoded_text[:num_batches_avail * char_per_batch]\n",
    "    \n",
    "    \n",
    "    # Reshape text into rows the size of a batch\n",
    "    encoded_text = encoded_text.reshape((samp_per_batch, -1))\n",
    "    \n",
    "\n",
    "    # Go through each row in array.\n",
    "    for n in range(0, encoded_text.shape[1], seq_len):\n",
    "        \n",
    "        # Grab feature characters\n",
    "        x = encoded_text[:, n:n+seq_len]\n",
    "        \n",
    "        # y is the target shifted over by 1\n",
    "        y = np.zeros_like(x)\n",
    "       \n",
    "        #\n",
    "        try:\n",
    "            y[:, :-1] = x[:, 1:]\n",
    "            y[:, -1]  = encoded_text[:, n+seq_len]\n",
    "            \n",
    "        # FOR POTENTIAL INDEXING ERROR AT THE END    \n",
    "        except:\n",
    "            y[:, :-1] = x[:, 1:]\n",
    "            y[:, -1] = encoded_text[:, 0]\n",
    "            \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f83b0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------Example of generating a batch-----------------------\n",
    "sample_text = np.arange(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49329816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5469a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = generate_batches(sample_text,samp_per_batch=2,seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4aba4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab first batch\n",
    "x, y = next(batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ed5f80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5074cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [11, 12, 13, 14, 15]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577ad61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae2eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1eae894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------Create LSTM Model--------------------------\n",
    "#rather similar as RNN but will be focused on the text itself\n",
    "\n",
    "class CharModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, all_chars, num_hidden=256, num_layers=4,drop_prob=0.5,use_gpu=False):\n",
    "        \n",
    "        \n",
    "        # SET UP ATTRIBUTES\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        #CHARACTER SET, ENCODER, and DECODER\n",
    "        self.all_chars = all_chars\n",
    "        self.decoder = dict(enumerate(all_chars))\n",
    "        self.encoder = {char: ind for ind,char in decoder.items()}\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(len(self.all_chars), num_hidden, num_layers, dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc_linear = nn.Linear(num_hidden, len(self.all_chars))\n",
    "      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "                  \n",
    "        \n",
    "        lstm_output, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        \n",
    "        drop_output = self.dropout(lstm_output)\n",
    "        \n",
    "        drop_output = drop_output.contiguous().view(-1, self.num_hidden)\n",
    "        \n",
    "        \n",
    "        final_out = self.fc_linear(drop_output)\n",
    "        \n",
    "        \n",
    "        return final_out, hidden\n",
    "    \n",
    "    \n",
    "    def hidden_state(self, batch_size):\n",
    "        '''\n",
    "        Used as separate method to account for both GPU and CPU users.\n",
    "        '''\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            \n",
    "            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda(),\n",
    "                     torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda())\n",
    "        else:\n",
    "            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden),\n",
    "                     torch.zeros(self.num_layers,batch_size,self.num_hidden))\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1607cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------Model Instance-----------------------------------\n",
    "model = CharModel(\n",
    "    all_chars=all_characters,\n",
    "    num_hidden=512,\n",
    "    num_layers=3,\n",
    "    drop_prob=0.5,\n",
    "    use_gpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1dadb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_param  = []\n",
    "for p in model.parameters():\n",
    "    total_param.append(int(p.numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a6094dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the total_parameters to be roughly the same magnitude as the number of characters in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4178086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5470292"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(total_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91de3aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3d7be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer and Loss fn\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "248a5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------Training and Validation of Data------------------\n",
    "# percentage of data to be used for training\n",
    "train_percent = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0775d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66b8b3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544560"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(encoded_text) * (train_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b95a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = int(len(encoded_text) * (train_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ddd03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = encoded_text[:train_ind]\n",
    "val_data = encoded_text[train_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2beab34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3298af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
